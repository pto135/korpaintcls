{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 크롤링"
      ],
      "metadata": {
        "id": "FD67r1och1UQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8_aAJJORmJW"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt_Jlhh9BADA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBV8mBOuBBTw"
      },
      "outputs": [],
      "source": [
        "FOLDERNAME = 'image_project5'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# Change dariectory to current folder\n",
        "%cd /content/drive/MyDrive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hrefs = []\n",
        "pagenums = 119\n",
        "baseurl = 'https://terms.naver.com/list.naver?cid=46702&categoryId=46739'\n",
        "for page in range(1, pagenums+1):\n",
        "    url = baseurl + f'&page={page}'\n",
        "    resp = requests.get(url, headers = headers)\n",
        "    soup = BeautifulSoup(resp.content, 'lxml')\n",
        "    links = soup.select('a.thumb_link')\n",
        "    for link in links:\n",
        "        href = re.search(r'href=\"([^\"]+)\"', str(link)).group(1)\n",
        "        hrefs.append(href)\n",
        "    time.sleep(0.5)"
      ],
      "metadata": {
        "id": "A0hgG-qMBRLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-M7ZFhYDUkf"
      },
      "outputs": [],
      "source": [
        "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCFFh_7zDNod"
      },
      "outputs": [],
      "source": [
        "content_list = []\n",
        "count = 0\n",
        "\n",
        "for href in tqdm(hrefs):\n",
        "    url = f'https://terms.naver.com/{href}'\n",
        "    resp = requests.get(url, headers=headers)\n",
        "\n",
        "    if (resp.status_code == 200) & ('categoryId=46739' in resp.url): # 그런 페이지가 존재한다면 진행\n",
        "        html = resp.content\n",
        "        soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "        content_dict = {}\n",
        "        content_dict[\"id\"] = doc_id\n",
        "\n",
        "        # 텍스트 정보\n",
        "        tmp_profile = soup.select('div.tmp_profile')\n",
        "        if tmp_profile:\n",
        "            for tr in tmp_profile[0].select('tr'):\n",
        "                if '<br/>' in str(tr.select('td')[0]): # 만약 여러 카테고리의 정보가 있다면\n",
        "                    beforethis = re.findall(\"<b>(.+?)</b>\", str(tr.select('td')[0]))[0] # 굵은 글씨로 된 단어(카테고리명) 중 첫번째\n",
        "                    content_dict[tr.select('th')[0].text] = re.findall(f\"(.+?){beforethis}\", tr.select('td')[0].text)[0] # .text 중에 그거 전까지만\n",
        "                    for category, content in zip(re.findall(\"<b>(.+?)</b>\", str(tr.select('td')[0])), re.findall(\"</b> (.+?)<\", str(tr.select('td')[0]))):\n",
        "                        content_dict[category] = content\n",
        "                else:\n",
        "                    content_dict[tr.select('th')[0].text] = tr.select('td')[0].text\n",
        "\n",
        "            content_list.append(content_dict)\n",
        "\n",
        "            # 이미지\n",
        "            img_url = soup.select('div.img_area img')[0]['src']\n",
        "            img_resp = requests.get(img_url)\n",
        "            with open(f'/content/drive/MyDrive/image_project5/data_naver_image/img_{doc_id}.png', 'wb') as f:\n",
        "                f.write(img_resp.content)\n",
        "\n",
        "    else: # 그런 페이지가 존재하지 않는다면\n",
        "        continue\n",
        "\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    if len(content_list) == 100:\n",
        "        with open(f\"/content/drive/MyDrive/image_project5/content_{count}00\", \"wb\") as fw:\n",
        "            pickle.dump(content_list, fw)\n",
        "        count += 1\n",
        "        content_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FYdr1r6yitn"
      },
      "outputs": [],
      "source": [
        "content_list_cplt = []\n",
        "for i in range(0, 20):\n",
        "    with open(f'/content/drive/MyDrive/image_project5/content_{i}00', 'rb') as f:\n",
        "        content_list_cplt += pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 추가 데이터 크롤링"
      ],
      "metadata": {
        "id": "3s7wquzJUKr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linkscrawling(artist):\n",
        "    baseurl, pagenums = artistdict[artist]\n",
        "    hrefs = []\n",
        "    for page in range(1, pagenums+1):\n",
        "        url = baseurl + f'&page={page}'\n",
        "        resp = requests.get(url, headers = headers)\n",
        "        soup = BeautifulSoup(resp.content, 'lxml')\n",
        "        links = soup.select('a.thumb_link')\n",
        "        for link in links:\n",
        "            href = re.search(r'href=\"([^\"]+)\"', str(link)).group(1)\n",
        "            hrefs.append(href)\n",
        "        time.sleep(0.5)\n",
        "    return hrefs\n",
        "\n",
        "artistdict = {'강연균' : ['https://terms.naver.com/artsSearch.naver?query=%EA%B0%95%EC%97%B0%EA%B7%A0+%EB%AF%B8%EC%88%A0%EC%9E%91%ED%92%88', 5],\n",
        "           '이해민선' : ['https://terms.naver.com/artsSearch.naver?query=%EC%9D%B4%ED%95%B4%EB%AF%BC%EC%84%A0+%EB%AF%B8%EC%88%A0%EC%9E%91%ED%92%88', 1],\n",
        "           '박수근' : ['https://terms.naver.com/artsSearch.naver?query=%EB%B0%95%EC%88%98%EA%B7%BC', 3],\n",
        "           '김환기' : ['https://terms.naver.com/artsSearch.naver?query=%EA%B9%80%ED%99%98%EA%B8%B0', 2],\n",
        "           '김명식' : ['https://terms.naver.com/artsSearch.naver?query=%EA%B9%80%EB%AA%85%EC%8B%9D+%EB%AF%B8%EC%88%A0%EC%9E%91%ED%92%88', 6],\n",
        "           '박영인' : ['https://terms.naver.com/artsSearch.naver?query=%EB%B0%95%EC%98%81%EC%9D%B8+%EB%AF%B8%EC%88%A0%EC%9E%91%ED%92%88', 4],\n",
        "            '유영국' : ['https://terms.naver.com/artsSearch.naver?query=%EC%9C%A0%EC%98%81%EA%B5%AD', 2],\n",
        "            '황술조' : ['https://terms.naver.com/artsSearch.naver?query=%ED%99%A9%EC%88%A0%EC%A1%B0', 1],\n",
        "            '이인성' : ['https://terms.naver.com/artsSearch.naver?query=%EC%9D%B4%EC%9D%B8%EC%84%B1', 1]}\n",
        "\n",
        "hrefs = []\n",
        "for artist in artistdict.keys() :\n",
        "    hrefs = hrefs + linkscrawling(artist)\n",
        "\n",
        "#이하 위와 동일하게 데이터 수집"
      ],
      "metadata": {
        "id": "h2Ceyg4LBV0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 작가 분류"
      ],
      "metadata": {
        "id": "136FHjeQRU9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "RGROc_3djGTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.9.0"
      ],
      "metadata": {
        "id": "oE8PgHviFRV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "V3Riqp3t7kPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "Y8lC2ux68STK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yaV2nkubiEv"
      },
      "outputs": [],
      "source": [
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ47WkbsnMIT"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DRUB2VbbbKo"
      },
      "outputs": [],
      "source": [
        "import splitfolders\n",
        "from tensorflow.keras.utils import image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "elpVs93NjusC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXyQ0dt_AxNL"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/image_project5/clean_content_list.pickle', 'rb') as f:\n",
        "    content_list = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8ONpSRsHIwk"
      },
      "outputs": [],
      "source": [
        "a = content_list['아티스트'].value_counts()[content_list['아티스트'].value_counts() > 100]\n",
        "content_list_artist = content_list[content_list['아티스트'].isin(a.index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrF8qRmzKXyF"
      },
      "outputs": [],
      "source": [
        "content_list_artist = content_list_artist.filter(items=['id', '아티스트'])\n",
        "content_list_artist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6N8m5qeMmZ_"
      },
      "outputs": [],
      "source": [
        "img_filedir = \"/content/drive/MyDrive/image_project5/data_naver_image\"\n",
        "content_list_artist['filepath'] = content_list_artist['id'].apply(lambda x : img_filedir + '/img_' + x + '.png')\n",
        "content_list_artist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-DOvEUcofaO"
      },
      "outputs": [],
      "source": [
        "widths_temp = []\n",
        "lengths_temp = []\n",
        "for img_path in content_list_artist['filepath']:\n",
        "    img = cv2.imread(img_path)\n",
        "    widths_temp.append(img.shape[0])\n",
        "    lengths_temp.append(img.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "widths_temp, lengths_temp = np.array(widths_temp), np.array(lengths_temp)"
      ],
      "metadata": {
        "id": "2ihKx0iffTXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for w, l in zip(widths_temp, lengths_temp) :\n",
        "    if (l * 2.42 < w) or (w * 2.42 < l) :\n",
        "        count += 1\n",
        "count"
      ],
      "metadata": {
        "id": "hBT9DpxkfRQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXHQpOEAo7yF"
      },
      "outputs": [],
      "source": [
        "display(np.mean(widths_temp), np.mean(lengths_temp))\n",
        "display(np.max(widths_temp), np.max(lengths_temp))\n",
        "display(np.min(widths_temp), np.min(lengths_temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZd6ehmptak2"
      },
      "outputs": [],
      "source": [
        "thres = 256\n",
        "content_list_artist.iloc[np.concatenate((np.where(widths_temp < thres)[0], np.where(lengths_temp < thres)[0]))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q69HDmSdssd4"
      },
      "outputs": [],
      "source": [
        "content_list_artist = content_list_artist.drop(index=content_list_artist.iloc[np.concatenate((np.where(widths_temp < thres)[0], np.where(lengths_temp < thres)[0]))].index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imutils"
      ],
      "metadata": {
        "id": "Gv7rUKloumR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpObecy6Q5O1"
      },
      "outputs": [],
      "source": [
        "img_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_and_resize_and_pad(img):\n",
        "    # ROTATE\n",
        "    if (img.shape[1] * 2.42 < img.shape[0]) or (img.shape[0] * 2.42 < img.shape[1]) :\n",
        "        img = imutils.rotate_bound(img, 45)\n",
        "\n",
        "    # RESIZE\n",
        "    if(img.shape[1] > img.shape[0]) :\n",
        "        ratio = img_size/img.shape[1]\n",
        "    else :\n",
        "        ratio = img_size/img.shape[0]\n",
        "    img = cv2.resize(img, dsize=(0, 0), fx=ratio, fy=ratio, interpolation=cv2.INTER_AREA) # INTER_LANCZOS4\n",
        "\n",
        "    # PAD\n",
        "    w, h = img.shape[1], img.shape[0]\n",
        "    dw, dh = (img_size-w)/2, (img_size-h)/2\n",
        "    M = np.float32([[1,0,dw], [0,1,dh]])\n",
        "    img_padded = cv2.warpAffine(img, M, (img_size, img_size))\n",
        "\n",
        "    return img_padded"
      ],
      "metadata": {
        "id": "s1dIJo9Eubwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtZwdzhORjrS"
      },
      "outputs": [],
      "source": [
        "label_names = content_list_artist['아티스트'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJchX2yjoAYt"
      },
      "outputs": [],
      "source": [
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_asdBMDpRc6H"
      },
      "outputs": [],
      "source": [
        "label2index = {}\n",
        "for i, name in enumerate(label_names):\n",
        "    label2index[name] = i\n",
        "label2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAEBEMB9hUXJ"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/resize')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J57O9gMKVTN"
      },
      "outputs": [],
      "source": [
        "for label in label_names:\n",
        "    dir_path = '/content/resize/'+ str(label2index[label])\n",
        "    os.mkdir(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywgLtPL_Q3-Q"
      },
      "outputs": [],
      "source": [
        "for img_path, label in tqdm(zip(content_list_artist['filepath'], content_list_artist['아티스트']), total=content_list_artist.shape[0]):\n",
        "    img = cv2.imread(img_path)\n",
        "    img_padded = rotate_and_resize_and_pad(img)\n",
        "    filename = img_path.split('/')[-1]\n",
        "    cv2.imwrite(f'/content/resize/{label2index[label]}/{filename}', img_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p5g0DZvZw0a"
      },
      "outputs": [],
      "source": [
        "splitfolders.ratio('/content/resize', output='dataset_224_rotate', seed=77, ratio=(0.8, 0.1, 0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khxnFM2LP_3U"
      },
      "outputs": [],
      "source": [
        "folder_path = \"/content/drive/MyDrive/image_project5/dataset_224_rotate\"\n",
        "for t in ['train', 'val', 'test']:\n",
        "    for label in label_names:\n",
        "        print(t, label, len(os.listdir(folder_path + '/' + t + '/' + str(label2index[label]))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터가 있는 폴더 경로 설정\n",
        "dataset_name = 'dataset_224_rotate'\n",
        "\n",
        "train_folder_path = \"/content/drive/MyDrive/image_project5/\" + dataset_name + \"/train\"\n",
        "val_folder_path = \"/content/drive/MyDrive/image_project5/\" + dataset_name + \"/val\"\n",
        "test_folder_path = \"/content/drive/MyDrive/image_project5/\" + dataset_name + \"/test\""
      ],
      "metadata": {
        "id": "PDYyB6W8E023"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mean img for zero-centering"
      ],
      "metadata": {
        "id": "IWgR4Gxqm2mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dirdict = {}\n",
        "for label in label_names:\n",
        "    filenames = os.listdir(train_folder_path + \"/\" + str(label2index[label]))\n",
        "    filenames = list(map(lambda filename : train_folder_path + \"/\" + str(label2index[label]) + \"/\" + filename, filenames))\n",
        "    train_dirdict[label2index[label]] = filenames"
      ],
      "metadata": {
        "id": "LuSp6R2JPSCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "for label in label_names:\n",
        "    for img_path in train_dirdict[label2index[label]]:\n",
        "        img = cv2.imread(img_path)\n",
        "        x_train.append(img)"
      ],
      "metadata": {
        "id": "BnRcW4hePZar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "metadata": {
        "id": "MaO4Hpj5PfEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_mean = lambda imgs : np.mean(imgs, axis=0)"
      ],
      "metadata": {
        "id": "uc5IJYgSRZ7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_img = compute_mean(x_train)"
      ],
      "metadata": {
        "id": "LgguVPe3Pt2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH3UCtn37s99"
      },
      "outputs": [],
      "source": [
        "mean_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlWdOVvaokLC"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/image_project5/mean_img_artist10_224_rotate.pickle\", \"wb\") as fw:\n",
        "    pickle.dump(mean_img, fw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train)"
      ],
      "metadata": {
        "id": "yVgRT4REQsFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_gray = tf.image.rgb_to_grayscale(x_train)"
      ],
      "metadata": {
        "id": "R6bO1TPm0FpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_gray.shape"
      ],
      "metadata": {
        "id": "9Q12B3AynzFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_img_gray = compute_mean(x_train_gray)"
      ],
      "metadata": {
        "id": "rzLXITSe0auI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_img_gray.shape"
      ],
      "metadata": {
        "id": "rND49EqTn1ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/image_project5/mean_img_artist10_224_rotate_gray.pickle\", \"wb\") as fw:\n",
        "    pickle.dump(mean_img_gray, fw)"
      ],
      "metadata": {
        "id": "5OUTsMXRQM9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mean img 불러오기(rgb와 grayscale 2개)\n",
        "with open('/content/drive/MyDrive/image_project5/mean_img_artist10_224_rotate.pickle', 'rb') as f:\n",
        "    mean_img = pickle.load(f)\n",
        "with open('/content/drive/MyDrive/image_project5/mean_img_artist10_224_rotate_gray.pickle', 'rb') as f:\n",
        "    mean_img_gray = pickle.load(f)"
      ],
      "metadata": {
        "id": "HJB8erTfniOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "zvULUvz6FEcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = image_dataset_from_directory(train_folder_path,\n",
        "                                            batch_size=batch_size,\n",
        "                                            image_size=(img_size, img_size),\n",
        "                                            shuffle=True,\n",
        "                                            seed=39,\n",
        "                                            interpolation='lanczos3')\n",
        "\n",
        "val_dataset = image_dataset_from_directory(val_folder_path,\n",
        "                                            batch_size=batch_size,\n",
        "                                            image_size=(img_size, img_size),\n",
        "                                            shuffle=True,\n",
        "                                            seed=39,\n",
        "                                            interpolation='lanczos3')\n",
        "\n",
        "test_dataset = image_dataset_from_directory(test_folder_path,\n",
        "                                            batch_size=batch_size,\n",
        "                                            image_size=(img_size, img_size),\n",
        "                                            shuffle=True,\n",
        "                                            seed=39,\n",
        "                                            interpolation='lanczos3')"
      ],
      "metadata": {
        "id": "gSyBHZUEn6w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델링"
      ],
      "metadata": {
        "id": "V0ukoH8-oKuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10"
      ],
      "metadata": {
        "id": "SFWJVY6J4uEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Base"
      ],
      "metadata": {
        "id": "prgCppsapyg-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOGgZ9p_US8m"
      },
      "outputs": [],
      "source": [
        "enb4 = tf.keras.applications.EfficientNetB4(include_top=False,\n",
        "                                            weights=\"imagenet\",\n",
        "                                            input_shape=None,\n",
        "                                            pooling=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hJk_Uj1M3Ut"
      },
      "outputs": [],
      "source": [
        "enb4.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUJD2OQ5M7qZ"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(img_size, img_size, 3,))\n",
        "x = sub_mean_img(inputs, mean_img)\n",
        "x = enb4(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x= tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZddSxgjTy6W"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNAk6xuRXcXZ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVd4WYIzXmvr"
      },
      "outputs": [],
      "source": [
        "# callbacks\n",
        "es = early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "poS3WNydPka0"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, batch_size=batch_size, validation_data=val_dataset, epochs=30,\n",
        "                    callbacks=[es])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model v2 (380)"
      ],
      "metadata": {
        "id": "HvB9lDb5plvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 380"
      ],
      "metadata": {
        "id": "wBUSioidYZEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixXs3sQGYYbz"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(img_size, img_size, 3,))\n",
        "x = sub_mean_img(inputs, mean_img)\n",
        "x = enb4(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x= tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hNe3tXZ3P-0"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl4TX4bU3P-1"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD5Z11mi3P-1"
      },
      "outputs": [],
      "source": [
        "# callbacks\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "ck = tf.keras.callbacks.ModelCheckpoint(filepath, verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3DwDgZq3P-1"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, batch_size=batch_size, validation_data=val_dataset, epochs=30,\n",
        "                    callbacks=[es, ck])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model v3 (grayscale)"
      ],
      "metadata": {
        "id": "g3bSpmmypZgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enb0_1 = tf.keras.applications.EfficientNetB0(include_top=False,\n",
        "                                            weights=\"imagenet\",\n",
        "                                            input_shape=None,\n",
        "                                            pooling=None)\n",
        "\n",
        "enb0_2 = tf.keras.applications.EfficientNetB0(include_top=False,\n",
        "                                            weights=\"imagenet\",\n",
        "                                            input_shape=None,\n",
        "                                            pooling=None)"
      ],
      "metadata": {
        "id": "jF2YYfq_zxjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류층만 학습시\n",
        "enb0_1.trainable = False\n",
        "enb0_2.trainable = False"
      ],
      "metadata": {
        "id": "7_jwWQ82f8xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enb0_1._name = \"efficientnetb0_1\"\n",
        "enb0_2._name = \"efficientnetb0_2\""
      ],
      "metadata": {
        "id": "rYGkt_gc2dg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(img_size, img_size, 3,))\n",
        "\n",
        "x_rgb = sub_mean_img(inputs, mean_img)\n",
        "x_rgb = enb0_1(x_rgb, training=False)\n",
        "x_rgb = tf.keras.layers.GlobalAveragePooling2D()(x_rgb)\n",
        "\n",
        "x_gray = tf.image.rgb_to_grayscale(inputs)\n",
        "x_gray = sub_mean_img(x_gray, mean_img_gray)\n",
        "x_gray = tf.repeat(x_gray, 3, axis=3)\n",
        "x_gray = enb0_2(x_gray, training=False)\n",
        "x_gray = tf.keras.layers.GlobalAveragePooling2D()(x_gray)\n",
        "\n",
        "x = tf.keras.layers.Concatenate(axis=-1)([x_rgb, x_gray])\n",
        "\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "HbqjpttjqhWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "i-nhNsvnxyK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "o-U1si8y1om5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYOR362q18-Y"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# tf.keras.optimizers.AdamW(learning_rate=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZDd7lJG18-Y"
      },
      "outputs": [],
      "source": [
        "# callbacks\n",
        "ck_path = \"/content/drive/MyDrive/image_project5/model_224_gray_onlytop\"\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "ck = tf.keras.callbacks.ModelCheckpoint(ck_path, verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, batch_size=batch_size, validation_data=val_dataset, epochs=30,\n",
        "                    callbacks=[es])"
      ],
      "metadata": {
        "id": "wnuBmWl6iPQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model v3-1 (rotate)"
      ],
      "metadata": {
        "id": "A8RrJSano_eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 재사용할 레이어\n",
        "dense = tf.keras.layers.Dense(256, activation='relu')\n",
        "\n",
        "# 연결\n",
        "inputs = tf.keras.Input(shape=(img_size, img_size, 3,))\n",
        "\n",
        "x_rgb = sub_mean_img(inputs, mean_img)\n",
        "x_rgb = enb0_1(x_rgb, training=False)\n",
        "x_rgb = tf.keras.layers.GlobalAveragePooling2D()(x_rgb)\n",
        "\n",
        "x_gray = tf.image.rgb_to_grayscale(inputs)\n",
        "x_gray = sub_mean_img(x_gray, mean_img_gray)\n",
        "x_gray = tf.repeat(x_gray, 3, axis=3)\n",
        "x_gray = enb0_2(x_gray, training=False)\n",
        "x_gray = tf.keras.layers.GlobalAveragePooling2D()(x_gray)\n",
        "\n",
        "x = tf.keras.layers.Concatenate(axis=-1)([x_rgb, x_gray]) # (, 2560)\n",
        "\n",
        "x = dense(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "6lyXZzeb3aWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "6y9QBQvk3aWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIrAFlX33aWV"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# tf.keras.optimizers.AdamW(learning_rate=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ck_path = \"/content/drive/MyDrive/image_project5/model_224_gray_rotate_onlytop\""
      ],
      "metadata": {
        "id": "_VcmUfQ73aWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aZUgdXi3aWW"
      },
      "outputs": [],
      "source": [
        "# callbacks\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "ck = tf.keras.callbacks.ModelCheckpoint(ck_path, verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaW_NYdG3aWW"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, batch_size=batch_size, validation_data=val_dataset, epochs=30,\n",
        "                    callbacks=[es, ck])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "44W5ySR7iZos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('onlytop_224_gray_rotate.h5')"
      ],
      "metadata": {
        "id": "BKd8lnPea7XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### weight 분석"
      ],
      "metadata": {
        "id": "RqH5nvFZoplS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치가 궁금해!\n",
        "model.layers[-3].weights[0]"
      ],
      "metadata": {
        "id": "fH4hURw7e7hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_weights = model.layers[-3].weights[0][:1280]\n",
        "gray_weights = model.layers[-3].weights[0][1280:]"
      ],
      "metadata": {
        "id": "CNNGyWQMpPeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_weights_np = np.array(rgb_weights)\n",
        "gray_weights_np = np.array(gray_weights)"
      ],
      "metadata": {
        "id": "op17MazwvwX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_weights_abs.sum(), gray_weights_abs.sum()"
      ],
      "metadata": {
        "id": "ZVNRE2KSAiOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(rgb_weights_abs), np.mean(gray_weights_abs)"
      ],
      "metadata": {
        "id": "-Qd0T8ugAnLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model v4 (augmentation)"
      ],
      "metadata": {
        "id": "85FhjO7Fp5BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.RandomBrightness(0.2, seed=39),\n",
        "        tf.keras.layers.RandomContrast(0.8, seed=39),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "K8I4agVoMESO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))"
      ],
      "metadata": {
        "id": "_mFClygdQKPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 재사용할 레이어\n",
        "dense = tf.keras.layers.Dense(256, activation='relu')\n",
        "\n",
        "# 연결\n",
        "inputs = tf.keras.Input(shape=(img_size, img_size, 3,))\n",
        "\n",
        "x_rgb = sub_mean_img(inputs, mean_img)\n",
        "x_rgb = enb0_1(x_rgb, training=False)\n",
        "x_rgb = tf.keras.layers.GlobalAveragePooling2D()(x_rgb)\n",
        "\n",
        "x_gray = tf.image.rgb_to_grayscale(inputs)\n",
        "x_gray = sub_mean_img(x_gray, mean_img_gray)\n",
        "x_gray = tf.repeat(x_gray, 3, axis=3)\n",
        "x_gray = enb0_2(x_gray, training=False)\n",
        "x_gray = tf.keras.layers.GlobalAveragePooling2D()(x_gray)\n",
        "\n",
        "x = tf.keras.layers.Concatenate(axis=-1)([x_rgb, x_gray])\n",
        "\n",
        "x = dense(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "7_6BadS_FsoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Wk7OMC_EFu3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Hj3RqOQKF2aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# callbacks\n",
        "ck_path = \"/content/drive/MyDrive/image_project5/model_224_gray_rotate_aug_onlytop\"\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "ck = tf.keras.callbacks.ModelCheckpoint(ck_path, verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "SZ8Ay_n7F46P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, batch_size=batch_size, validation_data=val_dataset, epochs=30,\n",
        "                    callbacks=[es, ck])"
      ],
      "metadata": {
        "id": "-4SRPOPxF6Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_224_gray_rotate_aug_onlytop.h5')"
      ],
      "metadata": {
        "id": "Pum9q4irF8-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "aYozJlNcGEJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model v5 (dropout 0.7)"
      ],
      "metadata": {
        "id": "dydWm1eip7zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 재사용할 레이어\n",
        "dense = tf.keras.layers.Dense(512, activation='relu')\n",
        "\n",
        "# 연결\n",
        "inputs = tf.keras.Input(shape=(img_size, img_size, 3,))\n",
        "\n",
        "x_rgb = sub_mean_img(inputs, mean_img)\n",
        "x_rgb = enb0_1(x_rgb, training=False)\n",
        "x_rgb = tf.keras.layers.GlobalAveragePooling2D()(x_rgb)\n",
        "\n",
        "x_gray = tf.image.rgb_to_grayscale(inputs)\n",
        "x_gray = sub_mean_img(x_gray, mean_img_gray)\n",
        "x_gray = tf.repeat(x_gray, 3, axis=3)\n",
        "x_gray = enb0_2(x_gray, training=False)\n",
        "x_gray = tf.keras.layers.GlobalAveragePooling2D()(x_gray)\n",
        "\n",
        "x = tf.keras.layers.Concatenate(axis=-1)([x_rgb, x_gray]) # (, 2560)\n",
        "\n",
        "x = dense(x)\n",
        "x = tf.keras.layers.Dropout(0.7)(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "ApP8mreDXN4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "yBVui3XWXN4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JrKazrGWXUzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# callbacks\n",
        "ck_path = \"/content/drive/MyDrive/image_project5/model_224_gray_rotate_dropout07_onlytop\"\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "ck = tf.keras.callbacks.ModelCheckpoint(ck_path, verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "BzrytWPJXUz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, batch_size=batch_size, validation_data=val_dataset, epochs=30,\n",
        "                    callbacks=[es, ck])"
      ],
      "metadata": {
        "id": "BWS0GzW0XUz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "UKRkPnhRXUz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_224_gray_rotate_dropout07_onlytop.h5')"
      ],
      "metadata": {
        "id": "t7Ae4t_1XUz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기법 분류"
      ],
      "metadata": {
        "id": "IX4dUZt4Rd18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA & 라벨 선정"
      ],
      "metadata": {
        "id": "wjJpUC01Rgxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/4조 이미지/plus_content.pickle', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "data = pd.DataFrame(data)\n",
        "data"
      ],
      "metadata": {
        "id": "FwvGG0HxCFzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['기법'].value_counts()"
      ],
      "metadata": {
        "id": "PNZ9rLavC8Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "76QyZexTFQrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_non_korean(word):\n",
        "    if pd.isna(word):\n",
        "        return word\n",
        "    else:\n",
        "        return re.sub('[^가-힣]', '', word)\n",
        "data['기법'] = data['기법'].apply(remove_non_korean)\n",
        "data['아티스트'] = data['아티스트'].apply(remove_non_korean)"
      ],
      "metadata": {
        "id": "svnnMdwqD0du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replaceword(preword, result):\n",
        "    try:\n",
        "        if result in preword :\n",
        "            return result\n",
        "        else :\n",
        "            return preword\n",
        "    except TypeError:\n",
        "        return preword\n",
        "\n",
        "data['기법'] = data['기법'].apply(lambda x: replaceword(x, '수채'))\n",
        "data['기법'] = data['기법'].apply(lambda x: replaceword(x, '유채'))\n",
        "\n",
        "combineword = {'종이에수묵' : '지본수묵',\n",
        "               '종이에수묵담채' : '지본담채',\n",
        "               '종이에수묵채색' : '지본채색',\n",
        "               '비단에채색' : '견본채색',\n",
        "               '비단에수묵담채' : '견본담채',\n",
        "               '비단에수묵' : '견본수묵',\n",
        "               '종이에먹' : '지본수묵',\n",
        "               '종이에담채' : '지본담채',\n",
        "               '지본수묵담채' : '지본담채',\n",
        "               '비단에수묵채색' : '견본채색',\n",
        "               '한지위에채색' : '한지에수묵채색',\n",
        "               '비단에먹' : '견본수묵',\n",
        "               '종이에채색' : '지본채색',\n",
        "               '지본수묵채색' : '지본채색'}\n",
        "\n",
        "data['기법'].replace(combineword, inplace = True)"
      ],
      "metadata": {
        "id": "w0ycQdlSD586"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리"
      ],
      "metadata": {
        "id": "VlugwQzPR2T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_zip = zipfile.ZipFile('/content/drive/MyDrive/4조 이미지/filtered_plus_image.zip')\n",
        "img_zip.extractall(path = '/content/filtered_plus_image')\n",
        "folder_path = '/content/filtered_plus_image'\n",
        "listdir = os.listdir(folder_path)\n",
        "id = [x[4:-4] for x in listdir]\n",
        "imgdict = {'id' : id,\n",
        "           'img_file' : listdir}\n",
        "data.drop('img_file',axis = 1, inplace = True)\n",
        "imgdf = pd.DataFrame(imgdict)\n",
        "data2= pd.merge(data, imgdf, how = 'outer')"
      ],
      "metadata": {
        "id": "HtACIizUFcls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2"
      ],
      "metadata": {
        "id": "hoMxQiqi0MqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2.dropna(subset = ['img_file'], inplace = True)\n",
        "color_data = data2[data2['기법'].isin(['지본채색', '지본담채', '지본수묵', '수채', '유채'])]\n",
        "color_data = color_data[['id','아티스트','기법', 'img_file']]"
      ],
      "metadata": {
        "id": "HtL9uVI4F9Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_data['기법'].value_counts()"
      ],
      "metadata": {
        "id": "Ps2vEd-mpbiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['지본채색', '지본담채', '지본수묵', '수채', '유채']\n",
        "majorlabel1 = color_data[color_data['기법'] == '지본수묵']\n",
        "majorlabel2 = color_data[color_data['기법'] == '지본담채']\n",
        "\n",
        "down_majorlabel1 = resample(majorlabel1, replace=False, n_samples=513, random_state=42)\n",
        "down_majorlabel2 = resample(majorlabel2, replace=False, n_samples=513, random_state=42)\n",
        "\n",
        "balanced_color_data = pd.concat([down_majorlabel1, down_majorlabel2,color_data[color_data['기법'].isin(['지본채색', '유채', '수채'])]])\n",
        "\n",
        "df = balanced_color_data"
      ],
      "metadata": {
        "id": "iBiuokL_GQDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Resizing, padding"
      ],
      "metadata": {
        "id": "8C1dig5Kx_GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#한 장의 이미지의 경로를 받아 resizing, padding하는 함수\n",
        "\n",
        "def resize(img_path, INTERPOL = cv2.INTER_AREA , img_size = 224):\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    #rotate\n",
        "    if (img.shape[1] * 2.42 < img.shape[0]) or (img.shape[0] * 2.42 < img.shape[1])   :\n",
        "        img = imutils.rotate_bound(img, 45)\n",
        "\n",
        "    #resize\n",
        "    if(img.shape[1] > img.shape[0]) :\n",
        "        ratio = img_size/img.shape[1]\n",
        "    else :\n",
        "        ratio = img_size/img.shape[0]\n",
        "    img = cv2.resize(img, dsize = (0,0), fx=ratio, fy=ratio, interpolation=INTERPOL)\n",
        "\n",
        "    #검은색으로 칠하기\n",
        "    w, h = img.shape[1], img.shape[0]\n",
        "\n",
        "    dw = (img_size-w)/2 # img_size와 w의 차이\n",
        "    dh = (img_size-h)/2 # img_size와 h의 차이\n",
        "\n",
        "    M = np.float32([[1,0,dw], [0,1,dh]])  #(2*3 이차원 행렬)\n",
        "    img = cv2.warpAffine(img, M, (img_size, img_size)) #이동변환\n",
        "\n",
        "    return img\n",
        "\n",
        "images, labels = [], []\n",
        "for idx in tqdm(range(len(df))):\n",
        "    id = df['id'].iloc[idx]\n",
        "    label = df['기법'].iloc[idx]\n",
        "    img_path = '/content//filtered_plus_image' + '/' + f'img_{id}.png'\n",
        "    images.append(resize(img_path, INTERPOL = cv2.INTER_LANCZOS4))\n",
        "    labels.append(label)"
      ],
      "metadata": {
        "id": "Ob5vEnnSHqkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라벨 인코딩, 이미지 생성, zero-centering"
      ],
      "metadata": {
        "id": "TxqGT4fTxz_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoded = label_encoder.fit_transform(labels)\n",
        "labels = tf.keras.utils.to_categorical(label_encoded)\n",
        "\n",
        "images_adj = tf.image.adjust_contrast(images, contrast_factor = 2.)\n",
        "\n",
        "#list라면 array 변환\n",
        "if isinstance(images, np.ndarray) == False:\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "#split\n",
        "x_data, x_val, y_data, y_val = train_test_split(images, labels,\n",
        "                                                    test_size=0.1,\n",
        "                                                    shuffle=True,\n",
        "                                                    random_state=42)\n",
        "\n",
        "#split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data,\n",
        "                                                    test_size=0.2,\n",
        "                                                    shuffle=True,\n",
        "                                                    random_state=42)\n",
        "\n",
        "np.save('/content/drive/MyDrive/backup/npy/x_train.npy', x_train)\n",
        "np.save('/content/drive/MyDrive/backup/npy/x_test.npy', x_test)\n",
        "np.save('/content/drive/MyDrive/backup/npy/x_val.npy', x_val)\n",
        "np.save('/content/drive/MyDrive/backup/npy/y_train.npy', y_train)\n",
        "np.save('/content/drive/MyDrive/backup/npy/y_test.npy', y_test)\n",
        "np.save('/content/drive/MyDrive/backup/npy/y_val.npy', y_val)"
      ],
      "metadata": {
        "id": "7DHAF1GjHzL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONTRAST\n",
        "x_train_adj = tf.image.adjust_contrast(x_train, contrast_factor = 1.5)\n",
        "x_test_adj = tf.image.adjust_contrast(x_test, contrast_factor = 1.5)\n",
        "\n",
        "np.save('/content/drive/MyDrive/backup/npy/x_train_adj.npy', x_train_adj)\n",
        "np.save('/content/drive/MyDrive/backup/npy/x_test_adj.npy', x_test_adj)\n",
        "\n",
        "compute_mean = lambda imgs : np.mean(imgs, axis=0).astype('int8')\n",
        "mean_img = compute_mean(x_train)\n",
        "mean_img_adj = compute_mean(x_train_adj)\n",
        "def sub_mean_img(imgs, mean_img):\n",
        "    return imgs - mean_img"
      ],
      "metadata": {
        "id": "KxZfCjHKH-uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRAYSCALE\n",
        "images_gray = []\n",
        "for image in images :\n",
        "    img_gray = rgb2gray(image)\n",
        "    img_gray = np.repeat(img_gray[:, :, np.newaxis], 3, axis = 2)\n",
        "    images_gray.append(img_gray)\n",
        "len(images_gray)"
      ],
      "metadata": {
        "id": "fuNlyXS7Z9Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델링"
      ],
      "metadata": {
        "id": "8Ki9Yz0WSSIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN : concat contrast-adjusted image\n",
        "num_classes = 5\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "base_model1 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3))\n",
        "base_model2 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3))\n",
        "Embedding_Layer = Dense(256, activation = 'relu', name = 'Embedding_Layer')\n",
        "\n",
        "base_model1._name = 'efficientnetb0_1'\n",
        "base_model2._name = 'efficientnetb0_2'\n",
        "\n",
        "input1 = tf.keras.Input(shape = (image_size, image_size, 3))\n",
        "input2 = tf.keras.Input(shape = (image_size, image_size, 3))\n",
        "\n",
        "x1 = sub_mean_img(input1, mean_img)\n",
        "x1 = base_model1(x1)\n",
        "x1 = GlobalAveragePooling2D()(x1)\n",
        "\n",
        "x2 = sub_mean_img(input2, mean_img_adj)\n",
        "x2 = base_model2(x2)\n",
        "x2 = GlobalAveragePooling2D()(x2)\n",
        "\n",
        "concat = tf.keras.layers.Concatenate(axis=-1)([x1,x2])\n",
        "concat = Dense(512, activation='relu')(concat)\n",
        "concat = Dropout(0.5)(concat)\n",
        "embedding = Embedding_Layer(concat)\n",
        "embedding = Dropout(0.5)(embedding)\n",
        "predictions = Dense(num_classes, activation='softmax')(embedding)\n",
        "\n",
        "model = Model(inputs=[input1, input2], outputs=predictions)\n",
        "\n",
        "\n",
        "# Freeze\n",
        "for layer in base_model1.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in base_model2.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "ck_path = \"/content/drive/MyDrive/backup/model\"\n",
        "ck = tf.keras.callbacks.ModelCheckpoint(ck_path, verbose=1, save_best_only=True)\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    [x_train, x_train_adj],\n",
        "    y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = 100,\n",
        "    validation_data = ([x_test, x_test_adj], y_test),\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    validation_steps=len(x_test) // batch_size,\n",
        "    callbacks=[early_stopping, ck]\n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/backup/style_contrast_2depth.h5')"
      ],
      "metadata": {
        "id": "2xBbWhLeIQUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grayscale concat 코드"
      ],
      "metadata": {
        "id": "UktzWt19acVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_gray, x_test_gray, y_train, y_test = split2center(images_gray, labels)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "base_model1 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3))\n",
        "base_model2 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3))\n",
        "\n",
        "base_model1._name = 'model1'\n",
        "base_model2._name = 'model2'\n",
        "\n",
        "input1 = tf.keras.Input(shape = (image_size, image_size, 3))\n",
        "input2 = tf.keras.Input(shape = (image_size, image_size, 3))\n",
        "\n",
        "x1 = base_model1(input1)\n",
        "x1 = GlobalAveragePooling2D()(x1)\n",
        "\n",
        "x2 = base_model2(input2)\n",
        "x2 = GlobalAveragePooling2D()(x2)\n",
        "\n",
        "concat = tf.keras.layers.Concatenate(axis=-1)([x1,x2])\n",
        "concat = Dense(256, activation='relu')(concat)\n",
        "concat = Dropout(0.3)(concat)\n",
        "predictions = Dense(num_classes, activation='softmax')(concat)\n",
        "\n",
        "model2 = Model(inputs=[input1, input2], outputs=predictions)\n",
        "\n",
        "# Freeze\n",
        "for layer in base_model1.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Freeze\n",
        "for layer in base_model2.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model2.fit(\n",
        "    [x_train, x_train_gray],\n",
        "    y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = 100,\n",
        "    validation_data = ([x_test, x_test_gray], y_test),\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    validation_steps=len(x_test) // batch_size,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "kCn2rZQ5ae2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Freeze 10% 해제 코드"
      ],
      "metadata": {
        "id": "_Lre9p4UZuhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "# Freeze 10% 해제 코드\n",
        "\n",
        "num_classes = 5\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "base_model1 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3))\n",
        "base_model2 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size, image_size, 3))\n",
        "Embedding_Layer = Dense(256, activation = 'relu', name = 'Embedding_Layer')\n",
        "\n",
        "base_model1._name = 'efficientnetb0_1'\n",
        "base_model2._name = 'efficientnetb0_2'\n",
        "\n",
        "input1 = tf.keras.Input(shape = (image_size, image_size, 3))\n",
        "input2 = tf.keras.Input(shape = (image_size, image_size, 3))\n",
        "\n",
        "x1 = sub_mean_img(input1, mean_img)\n",
        "x1 = base_model1(x1)\n",
        "x1 = GlobalAveragePooling2D()(x1)\n",
        "\n",
        "x2 = sub_mean_img(input2, mean_img_adj)\n",
        "x2 = base_model2(x2)\n",
        "x2 = GlobalAveragePooling2D()(x2)\n",
        "\n",
        "concat = tf.keras.layers.Concatenate(axis=-1)([x1,x2])\n",
        "concat = Dense(512, activation='relu')(concat)\n",
        "concat = Dropout(0.3)(concat)\n",
        "embedding = Embedding_Layer(concat)\n",
        "embedding = Dropout(0.2)(embedding)\n",
        "predictions = Dense(num_classes, activation='softmax')(embedding)\n",
        "\n",
        "model = Model(inputs=[input1, input2], outputs=predictions)\n",
        "\n",
        "\n",
        "# Freeze\n",
        "for layer in base_model1.layers[:-23]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Freeze\n",
        "for layer in base_model2.layers[:-23]:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in base_model1.layers[-23:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Freeze\n",
        "for layer in base_model2.layers[-23:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "ck_path = \"/content/drive/MyDrive/backup/model\"\n",
        "ck = tf.keras.callbacks.ModelCheckpoint(ck_path, verbose=1, save_best_only=True)\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    [x_train, x_train_adj],\n",
        "    y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = 100,\n",
        "    validation_data = ([x_test, x_test_adj], y_test),\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    validation_steps=len(x_test) // batch_size,\n",
        "    callbacks=[early_stopping, ck]\n",
        ")\n",
        "\n",
        "model.save('/content/drive/MyDrive/backup/melt_style_contrast_2depth.h5')"
      ],
      "metadata": {
        "id": "OTO0RRCiJRBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "W58VmEPWZ0CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_val_adj = tf.image.adjust_contrast(x_val, contrast_factor = 1.5)\n",
        "model.evaluate([x_val,x_val_adj], y_val)"
      ],
      "metadata": {
        "id": "E4lOPK5XJl6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Similarity"
      ],
      "metadata": {
        "id": "BeeS_QXV5ykG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/backup/style_contrast_2depth.h5)"
      ],
      "metadata": {
        "id": "YH_S9x7KJuAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = Model(inputs = [model.input[0], model.input[1]],\n",
        "                        outputs = model.get_layer('Embedding_Layer').output)\n",
        "\n",
        "embeddings = embedding_model.predict([x_train, x_train_adj])\n",
        "similarity_matrix = cosine_similarity(embeddings)"
      ],
      "metadata": {
        "id": "MbzSsz4GJv_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(query, num = 5, images = x_train):\n",
        "    # Recommend similar images\n",
        "    similar_images_indices = np.argsort(similarity_matrix[query])[::-1][1:num+1]  # Top 5 similar images\n",
        "\n",
        "    rows = int(np.sqrt(num))\n",
        "    cols = int(np.ceil(num / rows))\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
        "\n",
        "    similar_images = []\n",
        "    for index in similar_images_indices:\n",
        "        similar_images.append(images[index])\n",
        "\n",
        "    similar_images = [images[query]] + similar_images\n",
        "\n",
        "    print(\"Similar Images:\")\n",
        "    for i, image in enumerate(similar_images):\n",
        "        ax = axes[(i) // cols, (i) % cols]  # Get the current subplot\n",
        "        ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Plot the image\n",
        "        #ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oo30GRijJ1wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend(256)"
      ],
      "metadata": {
        "id": "Z0eofusJB3fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend(3)"
      ],
      "metadata": {
        "id": "pUA-0FOCFXQA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}